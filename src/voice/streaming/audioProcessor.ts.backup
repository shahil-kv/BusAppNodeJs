import { logger } from '../../utils/logger';

export interface AudioProcessingOptions {
    inputSampleRate: number;
    outputSampleRate: number;
    bitDepth: number;
    channels: number;
    normalize: boolean;
    amplification: number;
    strategy: 'simple' | 'interpolated' | 'filtered';
}

export class AudioProcessor {
    private static readonly DEFAULT_OPTIONS: AudioProcessingOptions = {
        inputSampleRate: 16000,
        outputSampleRate: 8000,
        bitDepth: 16,
        channels: 1,
        normalize: true,
        amplification: 1.0,
        strategy: 'interpolated'
    };

    /**
     * Convert audio from Gemini format to Twilio Media Streams format
     * Gemini: 16kHz, 16-bit, mono PCM
     * Twilio: 8kHz, 16-bit, mono PCM, little-endian
     */
    static processAudioForTwilio(
        inputBuffer: Buffer,
        options: Partial<AudioProcessingOptions> = {}
    ): Buffer {
        const opts = { ...this.DEFAULT_OPTIONS, ...options };

        try {
            logger.log(`[AudioProcessor] Processing audio: ${opts.inputSampleRate}Hz -> ${opts.outputSampleRate}Hz`);
            logger.log(`[AudioProcessor] Input buffer: ${inputBuffer.length} bytes`);

            // Validate input
            if (!inputBuffer || inputBuffer.length === 0) {
                logger.warn('[AudioProcessor] Empty input buffer');
                return Buffer.alloc(0);
            }

            // Check if input is all zeros (silence)
            const isSilence = inputBuffer.every(byte => byte === 0);
            if (isSilence) {
                logger.warn('[AudioProcessor] Input buffer contains only silence');
                return Buffer.alloc(0);
            }

            let processedBuffer: Buffer;

            // Choose processing strategy
            switch (opts.strategy) {
                case 'simple':
                    processedBuffer = this.simpleDownsample(inputBuffer, opts);
                    break;
                case 'interpolated':
                    processedBuffer = this.interpolatedDownsample(inputBuffer, opts);
                    break;
                case 'filtered':
                    processedBuffer = this.filteredDownsample(inputBuffer, opts);
                    break;
                default:
                    processedBuffer = this.interpolatedDownsample(inputBuffer, opts);
            }

            // Apply normalization and amplification
            if (opts.normalize || opts.amplification !== 1.0) {
                processedBuffer = this.normalizeAndAmplify(processedBuffer, opts);
            }

            logger.log(`[AudioProcessor] Output buffer: ${processedBuffer.length} bytes`);

            // Verify output quality
            this.verifyOutputQuality(processedBuffer);

            return processedBuffer;

        } catch (error) {
            logger.error('[AudioProcessor] Error processing audio:', error);
            return Buffer.alloc(0);
        }
    }

    /**
     * Simple downsampling: take every Nth sample
     */
    private static simpleDownsample(inputBuffer: Buffer, opts: AudioProcessingOptions): Buffer {
        const ratio = opts.inputSampleRate / opts.outputSampleRate;
        const inputSamples = inputBuffer.length / 2; // 16-bit = 2 bytes per sample
        const outputSamples = Math.floor(inputSamples / ratio);
        const outputBuffer = Buffer.alloc(outputSamples * 2);

        for (let i = 0; i < outputSamples; i++) {
            const inputIndex = Math.floor(i * ratio);
            const sample = inputBuffer.readInt16LE(inputIndex * 2);
            outputBuffer.writeInt16LE(sample, i * 2);
        }

        logger.log(`[AudioProcessor] Simple downsampling: ${inputSamples} -> ${outputSamples} samples`);
        return outputBuffer;
    }

    /**
     * Interpolated downsampling: average adjacent samples
     */
    private static interpolatedDownsample(inputBuffer: Buffer, opts: AudioProcessingOptions): Buffer {
        const ratio = opts.inputSampleRate / opts.outputSampleRate;
        const inputSamples = inputBuffer.length / 2;
        const outputSamples = Math.floor(inputSamples / ratio);
        const outputBuffer = Buffer.alloc(outputSamples * 2);

        for (let i = 0; i < outputSamples; i++) {
            const inputStart = Math.floor(i * ratio);
            const inputEnd = Math.min(Math.floor((i + 1) * ratio), inputSamples);

            // Average samples in the range
            let sum = 0;
            let count = 0;

            for (let j = inputStart; j < inputEnd; j++) {
                sum += inputBuffer.readInt16LE(j * 2);
                count++;
            }

            const averageSample = Math.round(sum / count);
            outputBuffer.writeInt16LE(averageSample, i * 2);
        }

        logger.log(`[AudioProcessor] Interpolated downsampling: ${inputSamples} -> ${outputSamples} samples`);
        return outputBuffer;
    }

    /**
     * Filtered downsampling: apply simple low-pass filter before downsampling
     */
    private static filteredDownsample(inputBuffer: Buffer, opts: AudioProcessingOptions): Buffer {
        const ratio = opts.inputSampleRate / opts.outputSampleRate;
        const inputSamples = inputBuffer.length / 2;
        const outputSamples = Math.floor(inputSamples / ratio);
        const outputBuffer = Buffer.alloc(outputSamples * 2);

        // Simple moving average filter
        const filterSize = Math.floor(ratio);
        const filteredSamples: number[] = [];

        for (let i = 0; i < inputSamples; i++) {
            let sum = 0;
            let count = 0;

            for (let j = Math.max(0, i - filterSize); j <= Math.min(inputSamples - 1, i + filterSize); j++) {
                sum += inputBuffer.readInt16LE(j * 2);
                count++;
            }

            filteredSamples.push(Math.round(sum / count));
        }

        // Downsample filtered samples
        for (let i = 0; i < outputSamples; i++) {
            const inputIndex = Math.floor(i * ratio);
            outputBuffer.writeInt16LE(filteredSamples[inputIndex], i * 2);
        }

        logger.log(`[AudioProcessor] Filtered downsampling: ${inputSamples} -> ${outputSamples} samples`);
        return outputBuffer;
    }

    /**
     * Normalize and amplify audio
     */
    private static normalizeAndAmplify(buffer: Buffer, opts: AudioProcessingOptions): Buffer {
        const samples = buffer.length / 2;
        const outputBuffer = Buffer.alloc(buffer.length);

        // Find max amplitude
        let maxAmplitude = 0;
        for (let i = 0; i < samples; i++) {
            const sample = Math.abs(buffer.readInt16LE(i * 2));
            maxAmplitude = Math.max(maxAmplitude, sample);
        }

        // Calculate normalization factor
        const targetMaxAmplitude = 16384; // 75% of 16-bit range
        const normalizationFactor = maxAmplitude > 0 ?
            Math.min(targetMaxAmplitude / maxAmplitude, 4.0) : 1.0;

        const totalFactor = normalizationFactor * opts.amplification;

        logger.log(`[AudioProcessor] Max amplitude: ${maxAmplitude}, Normalization factor: ${normalizationFactor.toFixed(2)}, Total factor: ${totalFactor.toFixed(2)}`);

        // Apply normalization and amplification
        for (let i = 0; i < samples; i++) {
            const sample = buffer.readInt16LE(i * 2);
            const processedSample = Math.round(sample * totalFactor);
            const clampedSample = Math.max(-32768, Math.min(32767, processedSample));
            outputBuffer.writeInt16LE(clampedSample, i * 2);
        }

        return outputBuffer;
    }

    /**
     * Verify output audio quality
     */
    private static verifyOutputQuality(buffer: Buffer): void {
        const samples = buffer.length / 2;

        if (samples === 0) {
            logger.warn('[AudioProcessor] Output buffer is empty');
            return;
        }

        // Check for silence
        const isSilence = buffer.every(byte => byte === 0);
        if (isSilence) {
            logger.warn('[AudioProcessor] Output buffer contains only silence');
            return;
        }

        // Check audio levels
        let maxAmplitude = 0;
        let rmsSum = 0;

        for (let i = 0; i < samples; i++) {
            const sample = Math.abs(buffer.readInt16LE(i * 2));
            maxAmplitude = Math.max(maxAmplitude, sample);
            rmsSum += sample * sample;
        }

        const rms = Math.sqrt(rmsSum / samples);

        logger.log(`[AudioProcessor] Quality check - Max amplitude: ${maxAmplitude}, RMS: ${rms.toFixed(0)}`);

        if (maxAmplitude < 1000) {
            logger.warn('[AudioProcessor] Audio levels are very low - may not be audible');
        } else if (maxAmplitude > 30000) {
            logger.warn('[AudioProcessor] Audio levels are very high - may cause distortion');
        } else {
            logger.log('[AudioProcessor] Audio levels look good');
        }
    }

    /**
     * Generate test tone for verification
     */
    static generateTestTone(frequency = 1000, duration = 2.0, sampleRate = 8000): Buffer {
        const samples = Math.floor(sampleRate * duration);
        const buffer = Buffer.alloc(samples * 2);

        for (let i = 0; i < samples; i++) {
            const sample = Math.sin(2 * Math.PI * frequency * i / sampleRate);
            const int16Sample = Math.floor(sample * 16384); // Scale to 16-bit range
            buffer.writeInt16LE(int16Sample, i * 2);
        }

        logger.log(`[AudioProcessor] Generated test tone: ${frequency}Hz, ${duration}s, ${samples} samples`);
        return buffer;
    }

    /**
     * Analyze audio buffer characteristics
     */
    static analyzeAudio(buffer: Buffer, sampleRate = 8000): any {
        const samples = buffer.length / 2;
        let maxAmplitude = 0;
        let minAmplitude = 0;
        let sum = 0;
        let zeroCrossings = 0;

        for (let i = 0; i < samples; i++) {
            const sample = buffer.readInt16LE(i * 2);
            maxAmplitude = Math.max(maxAmplitude, sample);
            minAmplitude = Math.min(minAmplitude, sample);
            sum += Math.abs(sample);

            if (i > 0) {
                const prevSample = buffer.readInt16LE((i - 1) * 2);
                if ((prevSample < 0 && sample >= 0) || (prevSample >= 0 && sample < 0)) {
                    zeroCrossings++;
                }
            }
        }

        const averageAmplitude = sum / samples;
        const duration = samples / sampleRate;

        return {
            samples,
            duration,
            maxAmplitude,
            minAmplitude,
            averageAmplitude,
            zeroCrossings,
            zeroCrossingRate: zeroCrossings / duration,
            isSilence: maxAmplitude === 0
        };
    }
} 